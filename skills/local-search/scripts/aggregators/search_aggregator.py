#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æœç´¢èšåˆå™¨ - å¤šå¼•æ“æœç´¢èšåˆ
"""

import sys
import os
sys.path.insert(0, os.path.dirname(os.path.dirname(__file__)))

from engines.base import SearchResult
from engines.google import GoogleSearchEngine
from engines.baidu import BaiduSearchEngine
from engines.duckduckgo import DuckDuckGoSearchEngine
from engines.github import GitHubSearchEngine
from typing import List, Dict, Optional
from config import SEARCH_ENGINES


class SearchAggregator:
    """æœç´¢èšåˆå™¨ - æ•´åˆå¤šä¸ªæœç´¢å¼•æ“çš„ç»“æœ"""

    def __init__(self):
        # åˆå§‹åŒ–æ‰€æœ‰æœç´¢å¼•æ“
        self.engines = {
            "google": GoogleSearchEngine(),
            "baidu": BaiduSearchEngine(),
            "duckduckgo": DuckDuckGoSearchEngine(),
            "github": GitHubSearchEngine()
        }

    def search(
        self,
        query: str,
        max_results: int = 10,
        engines: Optional[List[str]] = None
    ) -> List[SearchResult]:
        """
        å¤šå¼•æ“æœç´¢èšåˆ

        Args:
            query: æœç´¢å…³é”®è¯
            max_results: æ¯ä¸ªå¼•æ“çš„æœ€å¤§ç»“æœæ•°
            engines: æŒ‡å®šä½¿ç”¨çš„æœç´¢å¼•æ“åˆ—è¡¨ï¼ŒNone åˆ™ä½¿ç”¨æ‰€æœ‰å¯ç”¨å¼•æ“

        Returns:
            List[SearchResult]: èšåˆåçš„æœç´¢ç»“æœ
        """
        if engines is None:
            # ä½¿ç”¨é…ç½®ä¸­å¯ç”¨çš„æ‰€æœ‰å¼•æ“
            engines = [
                name for name, config in SEARCH_ENGINES.items()
                if config.get("enabled", True)
            ]

        all_results = []

        # æŒ‰ä¼˜å…ˆçº§æ’åºæœç´¢å¼•æ“
        engines_with_priority = [
            (name, SEARCH_ENGINES.get(name, {}).get("priority", 0))
            for name in engines
        ]
        engines_sorted = [e[0] for e in sorted(engines_with_priority, key=lambda x: -x[1])]

        # ä¾æ¬¡æ‰§è¡Œæœç´¢
        for engine_name in engines_sorted:
            if engine_name not in self.engines:
                continue

            engine = self.engines[engine_name]
            if not engine.is_available():
                print(f"âš ï¸  {engine.name} ä¸å¯ç”¨ï¼Œè·³è¿‡")
                continue

            print(f"ğŸ” ä½¿ç”¨ {engine.name} æœç´¢...")
            results = engine.search(query, max_results)
            all_results.extend(results)

        # å»é‡å’Œæ’åº
        unique_results = self._deduplicate(all_results)
        ranked_results = self._rank_by_relevance(unique_results, query)

        return ranked_results

    def _deduplicate(self, results: List[SearchResult]) -> List[SearchResult]:
        """
        ç»“æœå»é‡ï¼ˆåŸºäº URLï¼‰

        Args:
            results: åŸå§‹ç»“æœåˆ—è¡¨

        Returns:
            List[SearchResult]: å»é‡åçš„ç»“æœ
        """
        seen_urls = set()
        unique = []

        for result in results:
            # æ ‡å‡†åŒ– URLï¼ˆå»é™¤åè®®ã€wwwã€å°¾éƒ¨æ–œæ ç­‰ï¼‰
            normalized_url = self._normalize_url(result.url)

            if normalized_url not in seen_urls:
                seen_urls.add(normalized_url)
                unique.append(result)

        return unique

    def _normalize_url(self, url: str) -> str:
        """æ ‡å‡†åŒ– URL ç”¨äºå»é‡"""
        try:
            from urllib.parse import urlparse
            parsed = urlparse(url)
            # è¿”å› netloc + pathï¼ˆå¿½ç•¥åè®®å’Œå‚æ•°ï¼‰
            return f"{parsed.netloc}{parsed.path}".rstrip('/').lower()
        except Exception:
            return url.lower()

    def _rank_by_relevance(self, results: List[SearchResult], query: str) -> List[SearchResult]:
        """
        æŒ‰ç›¸å…³æ€§æ’åºç»“æœ

        Args:
            results: ç»“æœåˆ—è¡¨
            query: åŸå§‹æŸ¥è¯¢

        Returns:
            List[SearchResult]: æ’åºåçš„ç»“æœ
        """
        # ç®€å•çš„ç›¸å…³æ€§è¯„åˆ†ï¼šæ ‡é¢˜å’Œæ‘˜è¦ä¸­åŒ…å«æŸ¥è¯¢è¯çš„æ¬¡æ•°
        query_lower = query.lower()

        for result in results:
            score = 0
            title_lower = result.title.lower()
            snippet_lower = result.snippet.lower()

            # æ ‡é¢˜åŒ¹é…æƒé‡æ›´é«˜
            score += title_lower.count(query_lower) * 3
            score += snippet_lower.count(query_lower)

            # æ¥æºå¼•æ“æƒé‡
            engine_weights = {
                "Google": 1.5,
                "ç™¾åº¦": 1.2,
                "DuckDuckGo": 1.0,
                "GitHub": 2.0
            }
            score *= engine_weights.get(result.source, 1.0)

            result.score = score

        # æŒ‰åˆ†æ•°é™åºæ’åº
        return sorted(results, key=lambda r: r.score, reverse=True)

    def get_available_engines(self) -> Dict[str, bool]:
        """è·å–æ‰€æœ‰æœç´¢å¼•æ“çš„å¯ç”¨çŠ¶æ€"""
        return {
            name: engine.is_available()
            for name, engine in self.engines.items()
        }


# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    aggregator = SearchAggregator()

    print("=== å¯ç”¨æœç´¢å¼•æ“ ===")
    available = aggregator.get_available_engines()
    for name, is_avail in available.items():
        status = "âœ…" if is_avail else "âŒ"
        print(f"{status} {name}")

    print("\n=== å¤šå¼•æ“æœç´¢æµ‹è¯• ===")
    results = aggregator.search("æ­¦æ±‰å¤©æ°”", max_results=5)

    print(f"\nå…±æ‰¾åˆ° {len(results)} æ¡ç»“æœï¼ˆå·²å»é‡ã€æ’åºï¼‰\n")
    for i, r in enumerate(results[:10], 1):
        print(f"{i}. [{r.source}] {r.title}")
        print(f"   {r.url}")
        print(f"   è¯„åˆ†: {r.score:.1f} | {r.snippet[:60]}...")
        print()
