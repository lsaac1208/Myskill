---
name: awesome-workflow-engines
description: å·¥ä½œæµå¼•æ“æŸ¥è¯¢æ—¶è‡ªåŠ¨è§¦å‘ - workflow engineã€å·¥ä½œæµå¼•æ“ã€ä»»åŠ¡ç¼–æ’ã€workflowã€airflowã€argoã€dagsterã€ä»»åŠ¡è°ƒåº¦ã€‚ç²¾é€‰å¼€æºå·¥ä½œæµå¼•æ“åˆ—è¡¨ï¼Œæä¾›å„ç±»å·¥ä½œæµç¼–æ’å·¥å…·çš„æŸ¥è¯¢å’Œæœç´¢åŠŸèƒ½ã€‚
github_url: https://github.com/meirwah/awesome-workflow-engines
github_hash: 202f3b9fe7b467b22fa38f52438fb8a7a6f2d03e
version: 0.2.0
created_at: 2026-01-25T14:21:13.485033
updated_at: 2026-01-26
entry_point: scripts/wrapper.py
dependencies: []
license: Unknown
---

# Awesome Workflow Engines Skill

ç²¾é€‰å¼€æºå·¥ä½œæµå¼•æ“å¤§å…¨ï¼Œæ¶µç›–å„ç±»ä»»åŠ¡ç¼–æ’å’Œå·¥ä½œæµç®¡ç†å·¥å…·ã€‚

## ğŸ¯ é€‚ç”¨åœºæ™¯

å½“ç”¨æˆ·è¯·æ±‚ä»¥ä¸‹å†…å®¹æ—¶è‡ªåŠ¨æ¿€æ´»æ­¤ Skillï¼š

- **å·¥ä½œæµå¼•æ“**: "workflow engine"ã€"å·¥ä½œæµå¼•æ“"ã€"ä»»åŠ¡ç¼–æ’"
- **ä»»åŠ¡è°ƒåº¦**: "ä»»åŠ¡è°ƒåº¦"ã€"ä½œä¸šè°ƒåº¦"ã€"å®šæ—¶ä»»åŠ¡"
- **æ•°æ®ç®¡é“**: "æ•°æ®ç®¡é“"ã€"ETL"ã€"æ•°æ®å¤„ç†"
- **è‡ªåŠ¨åŒ–**: "æµç¨‹è‡ªåŠ¨åŒ–"ã€"ä¸šåŠ¡æµç¨‹"ã€"å·¥ä½œæµè‡ªåŠ¨åŒ–"

## âœ¨ æ ¸å¿ƒåŠŸèƒ½

- âœ… **åˆ†ç±»å…¨é¢**: æ¶µç›–å„ç±»å·¥ä½œæµå¼•æ“
- âœ… **æŠ€æœ¯å¤šæ ·**: æ”¯æŒå¤šç§ç¼–ç¨‹è¯­è¨€
- âœ… **åœºæ™¯ä¸°å¯Œ**: é€‚ç”¨äºä¸åŒä¸šåŠ¡åœºæ™¯
- âœ… **å¼€æºå…è´¹**: ç²¾é€‰å¼€æºé¡¹ç›®
- âœ… **ç¤¾åŒºæ´»è·ƒ**: æœ‰æ´»è·ƒçš„ç¤¾åŒºæ”¯æŒ
- âœ… **ç”Ÿäº§å°±ç»ª**: å¯ç”¨äºç”Ÿäº§ç¯å¢ƒ

## ğŸš€ å·¥ä½œæµå¼•æ“åˆ†ç±»

### ğŸ”¥ é€šç”¨å·¥ä½œæµå¼•æ“

#### Apache Airflow
**æè¿°**: æœ€æµè¡Œçš„æ•°æ®å·¥ä½œæµå¹³å°

**ç‰¹ç‚¹**:
- Python ç¼–å†™ï¼Œæ˜“äºæ‰©å±•
- ä¸°å¯Œçš„æ“ä½œç¬¦å’Œä¼ æ„Ÿå™¨
- å¼ºå¤§çš„è°ƒåº¦å’Œç›‘æ§
- æ´»è·ƒçš„ç¤¾åŒºå’Œç”Ÿæ€

**é€‚ç”¨åœºæ™¯**:
- æ•°æ®ç®¡é“ç¼–æ’
- ETL ä»»åŠ¡è°ƒåº¦
- æœºå™¨å­¦ä¹ å·¥ä½œæµ
- æ‰¹å¤„ç†ä»»åŠ¡

**ç¤ºä¾‹**:
```python
from airflow import DAG
from airflow.operators.python import PythonOperator
from datetime import datetime

def extract():
    print("Extracting data...")

def transform():
    print("Transforming data...")

def load():
    print("Loading data...")

with DAG(
    'etl_pipeline',
    start_date=datetime(2024, 1, 1),
    schedule_interval='@daily'
) as dag:

    extract_task = PythonOperator(
        task_id='extract',
        python_callable=extract
    )

    transform_task = PythonOperator(
        task_id='transform',
        python_callable=transform
    )

    load_task = PythonOperator(
        task_id='load',
        python_callable=load
    )

    extract_task >> transform_task >> load_task
```

#### Prefect
**æè¿°**: ç°ä»£åŒ–çš„æ•°æ®å·¥ä½œæµå¹³å°

**ç‰¹ç‚¹**:
- Python åŸç”Ÿï¼Œä»£ç å³é…ç½®
- åŠ¨æ€å·¥ä½œæµ
- äº‘åŸç”Ÿæ¶æ„
- ä¼˜ç§€çš„é”™è¯¯å¤„ç†

**é€‚ç”¨åœºæ™¯**:
- æ•°æ®å·¥ç¨‹
- MLOps
- è‡ªåŠ¨åŒ–è„šæœ¬
- å¤æ‚æ•°æ®ç®¡é“

**ç¤ºä¾‹**:
```python
from prefect import flow, task

@task
def extract():
    print("Extracting data...")
    return {"data": [1, 2, 3]}

@task
def transform(data):
    print("Transforming data...")
    return [x * 2 for x in data["data"]]

@task
def load(data):
    print(f"Loading data: {data}")

@flow
def etl_pipeline():
    raw_data = extract()
    transformed = transform(raw_data)
    load(transformed)

if __name__ == "__main__":
    etl_pipeline()
```

#### Temporal
**æè¿°**: å¯é çš„å¾®æœåŠ¡ç¼–æ’å¹³å°

**ç‰¹ç‚¹**:
- å¼ºå¤§çš„çŠ¶æ€ç®¡ç†
- è‡ªåŠ¨é‡è¯•å’Œæ¢å¤
- æ”¯æŒé•¿æ—¶é—´è¿è¡Œçš„å·¥ä½œæµ
- å¤šè¯­è¨€æ”¯æŒ

**é€‚ç”¨åœºæ™¯**:
- å¾®æœåŠ¡ç¼–æ’
- åˆ†å¸ƒå¼äº‹åŠ¡
- é•¿æ—¶é—´è¿è¡Œçš„ä¸šåŠ¡æµç¨‹
- å¯é çš„ä»»åŠ¡æ‰§è¡Œ

### â˜ï¸ äº‘åŸç”Ÿå·¥ä½œæµ

#### Argo Workflows
**æè¿°**: Kubernetes åŸç”Ÿçš„å·¥ä½œæµå¼•æ“

**ç‰¹ç‚¹**:
- å®¹å™¨åŸç”Ÿ
- DAG å’Œæ­¥éª¤å·¥ä½œæµ
- ä¸ Kubernetes æ·±åº¦é›†æˆ
- æ”¯æŒå¹¶è¡Œæ‰§è¡Œ

**é€‚ç”¨åœºæ™¯**:
- CI/CD æµæ°´çº¿
- æœºå™¨å­¦ä¹ è®­ç»ƒ
- æ‰¹å¤„ç†ä½œä¸š
- æ•°æ®å¤„ç†

**ç¤ºä¾‹**:
```yaml
apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: hello-world-
spec:
  entrypoint: whalesay
  templates:
  - name: whalesay
    container:
      image: docker/whalesay
      command: [cowsay]
      args: ["hello world"]
```

#### Flyte
**æè¿°**: å¯æ‰©å±•çš„æœºå™¨å­¦ä¹ å’Œæ•°æ®å¤„ç†å¹³å°

**ç‰¹ç‚¹**:
- å¼ºç±»å‹å·¥ä½œæµ
- ç‰ˆæœ¬æ§åˆ¶
- èµ„æºç®¡ç†
- å¤šäº‘æ”¯æŒ

**é€‚ç”¨åœºæ™¯**:
- æœºå™¨å­¦ä¹ å·¥ä½œæµ
- æ•°æ®å¤„ç†ç®¡é“
- æ‰¹é‡è®¡ç®—
- ç§‘å­¦è®¡ç®—

#### Tekton
**æè¿°**: Kubernetes åŸç”Ÿçš„ CI/CD æ¡†æ¶

**ç‰¹ç‚¹**:
- äº‘åŸç”Ÿ
- å¯é‡ç”¨çš„ç»„ä»¶
- å£°æ˜å¼é…ç½®
- ä¸ Kubernetes é›†æˆ

**é€‚ç”¨åœºæ™¯**:
- CI/CD æµæ°´çº¿
- å®¹å™¨æ„å»º
- åº”ç”¨éƒ¨ç½²
- è‡ªåŠ¨åŒ–æµ‹è¯•

### ğŸ“Š æ•°æ®å·¥ä½œæµ

#### Dagster
**æè¿°**: æ•°æ®ç¼–æ’å¹³å°

**ç‰¹ç‚¹**:
- æ•°æ®æ„ŸçŸ¥
- ç±»å‹ç³»ç»Ÿ
- æµ‹è¯•å’ŒéªŒè¯
- ä¸°å¯Œçš„ UI

**é€‚ç”¨åœºæ™¯**:
- æ•°æ®ç®¡é“
- æ•°æ®è´¨é‡
- æ•°æ®è½¬æ¢
- åˆ†æå·¥ä½œæµ

**ç¤ºä¾‹**:
```python
from dagster import asset, Definitions

@asset
def extract_data():
    return {"data": [1, 2, 3, 4, 5]}

@asset
def transform_data(extract_data):
    return [x * 2 for x in extract_data["data"]]

@asset
def load_data(transform_data):
    print(f"Loading: {transform_data}")

defs = Definitions(
    assets=[extract_data, transform_data, load_data]
)
```

#### Luigi
**æè¿°**: Python æ‰¹å¤„ç†æ¡†æ¶

**ç‰¹ç‚¹**:
- ç®€å•æ˜“ç”¨
- ä¾èµ–ç®¡ç†
- å¯è§†åŒ–ç•Œé¢
- è½»é‡çº§

**é€‚ç”¨åœºæ™¯**:
- æ‰¹å¤„ç†ä»»åŠ¡
- æ•°æ®ç®¡é“
- æŠ¥è¡¨ç”Ÿæˆ
- æ–‡ä»¶å¤„ç†

#### Kedro
**æè¿°**: æ•°æ®ç§‘å­¦å·¥ä½œæµæ¡†æ¶

**ç‰¹ç‚¹**:
- æ¨¡å—åŒ–è®¾è®¡
- æ•°æ®ç›®å½•
- ç®¡é“å¯è§†åŒ–
- æœ€ä½³å®è·µ

**é€‚ç”¨åœºæ™¯**:
- æ•°æ®ç§‘å­¦é¡¹ç›®
- æœºå™¨å­¦ä¹ ç®¡é“
- æ•°æ®å·¥ç¨‹
- å®éªŒç®¡ç†

### ğŸ¤– ä¸šåŠ¡æµç¨‹ç®¡ç†

#### Camunda
**æè¿°**: ä¼ä¸šçº§å·¥ä½œæµå’Œå†³ç­–è‡ªåŠ¨åŒ–å¹³å°

**ç‰¹ç‚¹**:
- BPMN 2.0 æ ‡å‡†
- DMN å†³ç­–å¼•æ“
- å¯è§†åŒ–å»ºæ¨¡
- ä¼ä¸šçº§åŠŸèƒ½

**é€‚ç”¨åœºæ™¯**:
- ä¸šåŠ¡æµç¨‹è‡ªåŠ¨åŒ–
- å®¡æ‰¹æµç¨‹
- è®¢å•å¤„ç†
- ä¼ä¸šåº”ç”¨é›†æˆ

#### Activiti
**æè¿°**: è½»é‡çº§çš„ä¸šåŠ¡æµç¨‹å¼•æ“

**ç‰¹ç‚¹**:
- BPMN 2.0 æ”¯æŒ
- Spring é›†æˆ
- æ˜“äºåµŒå…¥
- æ´»è·ƒç¤¾åŒº

**é€‚ç”¨åœºæ™¯**:
- å·¥ä½œæµç®¡ç†
- ä¸šåŠ¡æµç¨‹
- å®¡æ‰¹ç³»ç»Ÿ
- ä»»åŠ¡ç®¡ç†

#### Flowable
**æè¿°**: ç°ä»£åŒ–çš„ä¸šåŠ¡æµç¨‹å¼•æ“

**ç‰¹ç‚¹**:
- BPMNã€CMMNã€DMN æ”¯æŒ
- é«˜æ€§èƒ½
- äº‘å°±ç»ª
- ä¸°å¯Œçš„ API

**é€‚ç”¨åœºæ™¯**:
- å¤æ‚ä¸šåŠ¡æµç¨‹
- æ¡ˆä¾‹ç®¡ç†
- å†³ç­–è‡ªåŠ¨åŒ–
- æµç¨‹ä¼˜åŒ–

### ğŸ”„ äº‹ä»¶é©±åŠ¨å·¥ä½œæµ

#### Conductor (Netflix)
**æè¿°**: å¾®æœåŠ¡ç¼–æ’å¼•æ“

**ç‰¹ç‚¹**:
- å¯è§†åŒ–å·¥ä½œæµ
- åŠ¨æ€å·¥ä½œæµ
- ä»»åŠ¡é‡è¯•
- ç›‘æ§å’Œè¿½è¸ª

**é€‚ç”¨åœºæ™¯**:
- å¾®æœåŠ¡ç¼–æ’
- å¼‚æ­¥ä»»åŠ¡
- åˆ†å¸ƒå¼ç³»ç»Ÿ
- äº‹ä»¶å¤„ç†

#### Cadence (Uber)
**æè¿°**: åˆ†å¸ƒå¼ã€å¯æ‰©å±•çš„ç¼–æ’å¼•æ“

**ç‰¹ç‚¹**:
- å®¹é”™æ€§å¼º
- å¯æ‰©å±•
- çŠ¶æ€ç®¡ç†
- é•¿æ—¶é—´è¿è¡Œ

**é€‚ç”¨åœºæ™¯**:
- å¾®æœåŠ¡ç¼–æ’
- åˆ†å¸ƒå¼äº‹åŠ¡
- ä¸šåŠ¡æµç¨‹
- çŠ¶æ€æœº

### ğŸ¯ è½»é‡çº§å·¥ä½œæµ

#### n8n
**æè¿°**: å·¥ä½œæµè‡ªåŠ¨åŒ–å·¥å…·

**ç‰¹ç‚¹**:
- å¯è§†åŒ–ç¼–è¾‘å™¨
- ä¸°å¯Œçš„é›†æˆ
- è‡ªæ‰˜ç®¡
- æ˜“äºä½¿ç”¨

**é€‚ç”¨åœºæ™¯**:
- è‡ªåŠ¨åŒ–ä»»åŠ¡
- API é›†æˆ
- æ•°æ®åŒæ­¥
- é€šçŸ¥å’Œæé†’

#### Windmill
**æè¿°**: å¼€æºçš„å¼€å‘è€…å¹³å°

**ç‰¹ç‚¹**:
- ä»£ç å³å·¥ä½œæµ
- å¤šè¯­è¨€æ”¯æŒ
- è‡ªåŠ¨ç”Ÿæˆ UI
- å¿«é€Ÿéƒ¨ç½²

**é€‚ç”¨åœºæ™¯**:
- å†…éƒ¨å·¥å…·
- è‡ªåŠ¨åŒ–è„šæœ¬
- API ç¼–æ’
- æ•°æ®å¤„ç†

## ğŸ“‹ å·¥ä½œæµå¼•æ“å¯¹æ¯”

### æŒ‰è¯­è¨€åˆ†ç±»

| è¯­è¨€ | å·¥ä½œæµå¼•æ“ |
|------|-----------|
| **Python** | Airflow, Prefect, Dagster, Luigi, Kedro |
| **Go** | Temporal, Cadence, Argo Workflows |
| **Java** | Camunda, Activiti, Flowable, Conductor |
| **JavaScript** | n8n, Node-RED |
| **å¤šè¯­è¨€** | Temporal, Flyte, Argo Workflows |

### æŒ‰åœºæ™¯åˆ†ç±»

| åœºæ™¯ | æ¨èå¼•æ“ |
|------|---------|
| **æ•°æ®ç®¡é“** | Airflow, Prefect, Dagster |
| **æœºå™¨å­¦ä¹ ** | Flyte, Kubeflow, Metaflow |
| **CI/CD** | Argo Workflows, Tekton, Jenkins X |
| **å¾®æœåŠ¡ç¼–æ’** | Temporal, Conductor, Cadence |
| **ä¸šåŠ¡æµç¨‹** | Camunda, Activiti, Flowable |
| **è‡ªåŠ¨åŒ–ä»»åŠ¡** | n8n, Windmill, Zapier |

### æŒ‰è§„æ¨¡åˆ†ç±»

| è§„æ¨¡ | æ¨èå¼•æ“ |
|------|---------|
| **å°å‹é¡¹ç›®** | Luigi, n8n, Windmill |
| **ä¸­å‹é¡¹ç›®** | Prefect, Dagster, Argo Workflows |
| **å¤§å‹é¡¹ç›®** | Airflow, Temporal, Camunda |
| **ä¼ä¸šçº§** | Camunda, Flowable, Temporal |

## ğŸ”§ é€‰æ‹©æŒ‡å—

### æ•°æ®å·¥ç¨‹åœºæ™¯

**æ¨è**: Airflow, Prefect, Dagster

**ç†ç”±**:
- ä¸“ä¸ºæ•°æ®ç®¡é“è®¾è®¡
- ä¸°å¯Œçš„æ•°æ®æºé›†æˆ
- å¼ºå¤§çš„è°ƒåº¦åŠŸèƒ½
- å®Œå–„çš„ç›‘æ§å’Œå‘Šè­¦

**é€‰æ‹©å»ºè®®**:
```markdown
- **Airflow**: æˆç†Ÿç¨³å®šï¼Œç”Ÿæ€ä¸°å¯Œï¼Œé€‚åˆå¤§è§„æ¨¡æ•°æ®ç®¡é“
- **Prefect**: ç°ä»£åŒ–è®¾è®¡ï¼Œæ˜“äºä½¿ç”¨ï¼Œé€‚åˆå¿«é€Ÿå¼€å‘
- **Dagster**: æ•°æ®æ„ŸçŸ¥ï¼Œç±»å‹å®‰å…¨ï¼Œé€‚åˆæ•°æ®è´¨é‡è¦æ±‚é«˜çš„åœºæ™¯
```

### æœºå™¨å­¦ä¹ åœºæ™¯

**æ¨è**: Flyte, Kubeflow, Metaflow

**ç†ç”±**:
- æ”¯æŒ GPU èµ„æºç®¡ç†
- å®éªŒè¿½è¸ª
- æ¨¡å‹ç‰ˆæœ¬æ§åˆ¶
- åˆ†å¸ƒå¼è®­ç»ƒ

**é€‰æ‹©å»ºè®®**:
```markdown
- **Flyte**: å¼ºç±»å‹ï¼Œç‰ˆæœ¬æ§åˆ¶ï¼Œé€‚åˆå¤§è§„æ¨¡ ML å·¥ä½œæµ
- **Kubeflow**: Kubernetes åŸç”Ÿï¼Œå®Œæ•´çš„ ML å¹³å°
- **Metaflow**: ç®€å•æ˜“ç”¨ï¼Œé€‚åˆæ•°æ®ç§‘å­¦å®¶
```

### å¾®æœåŠ¡ç¼–æ’åœºæ™¯

**æ¨è**: Temporal, Conductor, Cadence

**ç†ç”±**:
- å¯é çš„çŠ¶æ€ç®¡ç†
- è‡ªåŠ¨é‡è¯•å’Œæ¢å¤
- æ”¯æŒé•¿æ—¶é—´è¿è¡Œ
- åˆ†å¸ƒå¼äº‹åŠ¡

**é€‰æ‹©å»ºè®®**:
```markdown
- **Temporal**: åŠŸèƒ½æœ€å…¨ï¼Œç¤¾åŒºæ´»è·ƒï¼Œé€‚åˆå¤æ‚åœºæ™¯
- **Conductor**: å¯è§†åŒ–å¥½ï¼Œæ˜“äºç›‘æ§ï¼Œé€‚åˆå¾®æœåŠ¡ç¼–æ’
- **Cadence**: Uber å‡ºå“ï¼Œç¨³å®šå¯é ï¼Œé€‚åˆå¤§è§„æ¨¡éƒ¨ç½²
```

### ä¸šåŠ¡æµç¨‹åœºæ™¯

**æ¨è**: Camunda, Activiti, Flowable

**ç†ç”±**:
- BPMN æ ‡å‡†æ”¯æŒ
- å¯è§†åŒ–å»ºæ¨¡
- ä¼ä¸šçº§åŠŸèƒ½
- å®¡æ‰¹æµç¨‹

**é€‰æ‹©å»ºè®®**:
```markdown
- **Camunda**: åŠŸèƒ½æœ€å…¨ï¼Œä¼ä¸šçº§ï¼Œé€‚åˆå¤æ‚ä¸šåŠ¡æµç¨‹
- **Activiti**: è½»é‡çº§ï¼Œæ˜“äºé›†æˆï¼Œé€‚åˆä¸­å°å‹é¡¹ç›®
- **Flowable**: ç°ä»£åŒ–ï¼Œæ€§èƒ½å¥½ï¼Œé€‚åˆäº‘åŸç”Ÿåº”ç”¨
```

## ğŸ“ å®ç”¨ç¤ºä¾‹

### ç¤ºä¾‹ 1: Airflow ETL ç®¡é“

```python
from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.providers.postgres.operators.postgres import PostgresOperator
from datetime import datetime, timedelta

default_args = {
    'owner': 'data-team',
    'depends_on_past': False,
    'start_date': datetime(2024, 1, 1),
    'email_on_failure': True,
    'email_on_retry': False,
    'retries': 3,
    'retry_delay': timedelta(minutes=5),
}

def extract_from_api():
    # ä» API æå–æ•°æ®
    import requests
    response = requests.get('https://api.example.com/data')
    return response.json()

def transform_data(**context):
    # è½¬æ¢æ•°æ®
    data = context['task_instance'].xcom_pull(task_ids='extract')
    transformed = [{'id': item['id'], 'value': item['value'] * 2}
                   for item in data]
    return transformed

with DAG(
    'etl_pipeline',
    default_args=default_args,
    description='ETL pipeline example',
    schedule_interval='@daily',
    catchup=False
) as dag:

    extract = PythonOperator(
        task_id='extract',
        python_callable=extract_from_api
    )

    transform = PythonOperator(
        task_id='transform',
        python_callable=transform_data,
        provide_context=True
    )

    load = PostgresOperator(
        task_id='load',
        postgres_conn_id='postgres_default',
        sql="""
            INSERT INTO target_table (id, value)
            VALUES {{ task_instance.xcom_pull(task_ids='transform') }}
        """
    )

    extract >> transform >> load
```

### ç¤ºä¾‹ 2: Prefect æ•°æ®ç®¡é“

```python
from prefect import flow, task
from prefect.tasks import task_input_hash
from datetime import timedelta
import pandas as pd

@task(cache_key_fn=task_input_hash, cache_expiration=timedelta(hours=1))
def extract_data(source: str):
    """ä»æ•°æ®æºæå–æ•°æ®"""
    df = pd.read_csv(source)
    return df

@task
def clean_data(df: pd.DataFrame):
    """æ¸…æ´—æ•°æ®"""
    df = df.dropna()
    df = df.drop_duplicates()
    return df

@task
def transform_data(df: pd.DataFrame):
    """è½¬æ¢æ•°æ®"""
    df['value'] = df['value'] * 2
    df['category'] = df['category'].str.upper()
    return df

@task
def load_data(df: pd.DataFrame, destination: str):
    """åŠ è½½æ•°æ®åˆ°ç›®æ ‡"""
    df.to_csv(destination, index=False)
    return len(df)

@flow(name="data-pipeline")
def data_pipeline(source: str, destination: str):
    """å®Œæ•´çš„æ•°æ®ç®¡é“"""
    raw_data = extract_data(source)
    cleaned_data = clean_data(raw_data)
    transformed_data = transform_data(cleaned_data)
    rows_loaded = load_data(transformed_data, destination)

    return f"Successfully loaded {rows_loaded} rows"

if __name__ == "__main__":
    data_pipeline(
        source="data/input.csv",
        destination="data/output.csv"
    )
```

### ç¤ºä¾‹ 3: Temporal å¾®æœåŠ¡ç¼–æ’

```python
from temporalio import workflow, activity
from datetime import timedelta

@activity.defn
async def process_payment(order_id: str, amount: float):
    """å¤„ç†æ”¯ä»˜"""
    # è°ƒç”¨æ”¯ä»˜æœåŠ¡
    print(f"Processing payment for order {order_id}: ${amount}")
    return {"status": "success", "transaction_id": "txn_123"}

@activity.defn
async def update_inventory(order_id: str, items: list):
    """æ›´æ–°åº“å­˜"""
    print(f"Updating inventory for order {order_id}")
    return {"status": "updated"}

@activity.defn
async def send_notification(order_id: str, email: str):
    """å‘é€é€šçŸ¥"""
    print(f"Sending notification to {email} for order {order_id}")
    return {"status": "sent"}

@workflow.defn
class OrderWorkflow:
    @workflow.run
    async def run(self, order_id: str, amount: float, items: list, email: str):
        # å¤„ç†æ”¯ä»˜
        payment_result = await workflow.execute_activity(
            process_payment,
            args=[order_id, amount],
            start_to_close_timeout=timedelta(seconds=30),
        )

        if payment_result["status"] != "success":
            raise Exception("Payment failed")

        # æ›´æ–°åº“å­˜
        await workflow.execute_activity(
            update_inventory,
            args=[order_id, items],
            start_to_close_timeout=timedelta(seconds=30),
        )

        # å‘é€é€šçŸ¥
        await workflow.execute_activity(
            send_notification,
            args=[order_id, email],
            start_to_close_timeout=timedelta(seconds=30),
        )

        return {"order_id": order_id, "status": "completed"}
```

## ğŸ› å¸¸è§é—®é¢˜

### 1. å¦‚ä½•é€‰æ‹©åˆé€‚çš„å·¥ä½œæµå¼•æ“ï¼Ÿ

**è€ƒè™‘å› ç´ **:
```markdown
1. **ä½¿ç”¨åœºæ™¯**: æ•°æ®ç®¡é“ã€å¾®æœåŠ¡ç¼–æ’ã€ä¸šåŠ¡æµç¨‹ï¼Ÿ
2. **æŠ€æœ¯æ ˆ**: å›¢é˜Ÿç†Ÿæ‚‰çš„ç¼–ç¨‹è¯­è¨€
3. **è§„æ¨¡**: ä»»åŠ¡æ•°é‡ã€å¹¶å‘åº¦ã€æ•°æ®é‡
4. **éƒ¨ç½²ç¯å¢ƒ**: äº‘ã€æœ¬åœ°ã€Kubernetes
5. **é¢„ç®—**: å¼€æºã€å•†ä¸šã€æ‰˜ç®¡æœåŠ¡
```

### 2. å·¥ä½œæµå¼•æ“æ€§èƒ½é—®é¢˜

**ç—‡çŠ¶**: ä»»åŠ¡æ‰§è¡Œç¼“æ…¢ã€è°ƒåº¦å»¶è¿Ÿ

**è§£å†³æ–¹æ¡ˆ**:
```markdown
- **å¢åŠ èµ„æº**: æ‰©å±• worker æ•°é‡
- **ä¼˜åŒ–ä»»åŠ¡**: å‡å°‘ä»»åŠ¡ç²’åº¦ï¼Œé¿å…è¿‡åº¦ä¾èµ–
- **ä½¿ç”¨ç¼“å­˜**: ç¼“å­˜ä¸­é—´ç»“æœ
- **å¹¶è¡Œæ‰§è¡Œ**: åˆ©ç”¨å¹¶è¡Œèƒ½åŠ›
- **ç›‘æ§è°ƒä¼˜**: ä½¿ç”¨ç›‘æ§å·¥å…·æ‰¾å‡ºç“¶é¢ˆ
```

### 3. å·¥ä½œæµå¤±è´¥å¤„ç†

**ç—‡çŠ¶**: ä»»åŠ¡å¤±è´¥åå¦‚ä½•æ¢å¤

**è§£å†³æ–¹æ¡ˆ**:
```markdown
- **è‡ªåŠ¨é‡è¯•**: é…ç½®é‡è¯•ç­–ç•¥
- **å‘Šè­¦é€šçŸ¥**: è®¾ç½®å¤±è´¥å‘Šè­¦
- **å¹‚ç­‰æ€§**: ç¡®ä¿ä»»åŠ¡å¯é‡å¤æ‰§è¡Œ
- **æ£€æŸ¥ç‚¹**: ä¿å­˜ä¸­é—´çŠ¶æ€
- **æ‰‹åŠ¨å¹²é¢„**: æä¾›æ‰‹åŠ¨é‡è¯•æœºåˆ¶
```

### 4. å·¥ä½œæµç›‘æ§å’Œè°ƒè¯•

**ç—‡çŠ¶**: éš¾ä»¥è¿½è¸ªå·¥ä½œæµæ‰§è¡ŒçŠ¶æ€

**è§£å†³æ–¹æ¡ˆ**:
```markdown
- **æ—¥å¿—è®°å½•**: è¯¦ç»†çš„æ—¥å¿—è¾“å‡º
- **å¯è§†åŒ–**: ä½¿ç”¨ UI æŸ¥çœ‹å·¥ä½œæµ
- **æŒ‡æ ‡ç›‘æ§**: æ”¶é›†æ‰§è¡ŒæŒ‡æ ‡
- **è¿½è¸ªç³»ç»Ÿ**: é›†æˆåˆ†å¸ƒå¼è¿½è¸ª
- **å‘Šè­¦ç³»ç»Ÿ**: è®¾ç½®å…³é”®æŒ‡æ ‡å‘Šè­¦
```

## ğŸ“– å­¦ä¹ èµ„æº

### å®˜æ–¹æ–‡æ¡£

- **Airflow**: https://airflow.apache.org/docs/
- **Prefect**: https://docs.prefect.io/
- **Temporal**: https://docs.temporal.io/
- **Argo Workflows**: https://argoproj.github.io/workflows/
- **Dagster**: https://docs.dagster.io/
- **Camunda**: https://docs.camunda.org/

### æ•™ç¨‹å’Œç¤ºä¾‹

- **Airflow æ•™ç¨‹**: https://github.com/apache/airflow/tree/main/airflow/example_dags
- **Prefect ç¤ºä¾‹**: https://github.com/PrefectHQ/prefect/tree/main/examples
- **Temporal ç¤ºä¾‹**: https://github.com/temporalio/samples-python

### ç¤¾åŒºèµ„æº

- **Awesome Workflow Engines**: https://github.com/meirwah/awesome-workflow-engines
- **å·¥ä½œæµå¼•æ“å¯¹æ¯”**: https://github.com/common-workflow-language/common-workflow-language
- **æœ€ä½³å®è·µ**: å„å¼•æ“å®˜æ–¹æ–‡æ¡£çš„æœ€ä½³å®è·µéƒ¨åˆ†

## ğŸ“– å‚è€ƒèµ„æ–™

- **GitHub ä»“åº“**: https://github.com/meirwah/awesome-workflow-engines
- **å·¥ä½œæµæ¨¡å¼**: http://www.workflowpatterns.com/
- **BPMN è§„èŒƒ**: https://www.omg.org/spec/BPMN/

## ğŸ“ æ›´æ–°æ—¥å¿—

### v0.2.0 (2026-01-26)
- âœ¨ æ›´æ–°åˆ°æœ€æ–°ç‰ˆæœ¬ (202f3b9)
- ğŸ“ å®Œå–„æ–‡æ¡£å’Œå¼•æ“åˆ†ç±»
- âœ¨ æ·»åŠ è¯¦ç»†çš„å¼•æ“ä»‹ç»
- âœ¨ æ·»åŠ é€‰æ‹©æŒ‡å—å’Œå¯¹æ¯”
- âœ¨ æ·»åŠ å®ç”¨ç¤ºä¾‹ä»£ç 
- âœ¨ æ·»åŠ å¸¸è§é—®é¢˜è§£ç­”

### v0.1.0 (2026-01-25)
- ğŸ‰ åˆå§‹ç‰ˆæœ¬
